{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f49c4f4e-f8a0-47cb-b288-d9426b4cec3f",
   "metadata": {},
   "source": [
    "### Template for enabling existing code to run efficiently on NERSC (gpt-engineer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1471068-ea0f-4451-b4f1-c9f62df52827",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Fill in the project name and existing code location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c686aa3c-2f63-4662-9a00-560d03e2005e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_name = \"enter_project_name\"\n",
    "existing_code_location = \"path_to_directory_to_import\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f65e5a-27da-49a3-a644-303c01069988",
   "metadata": {},
   "source": [
    "#### Set up the AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b742baa0-0ffe-4dc4-b53d-25a811e7b42a",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import gpt_engineer.steps as steps\n",
    "from gpt_engineer.ai import AI, fallback_model\n",
    "from gpt_engineer.db import DB, DBs\n",
    "\n",
    "problem_statement = '''I have this scientific computation that I wrote. \n",
    "I would like to optimize it such that it runs faster (utilizing parallel computation) and is more interactive.\n",
    "I will be running this on an HPC system that has support for dask and slurm.\n",
    "I will want to interact with the computation via a Jupyter notebook.\n",
    "'''\n",
    "\n",
    "def set_up(project_name, existing_code_location):\n",
    "    input_path = Path(project_name)\n",
    "    input_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    prompt_file = input_path / \"prompt\"\n",
    "\n",
    "    with open(prompt_file, \"w\") as file:\n",
    "        file.write(problem_statement)\n",
    "\n",
    "    input_path = input_path.absolute()\n",
    "    print(\"The following location will be used for processing\\nThe code will be output to the workspace directory of that location\")\n",
    "    print(input_path)\n",
    "    \n",
    "    model = \"gpt-4\"\n",
    "    temperature = 0.1\n",
    "    model = fallback_model(model)\n",
    "    ai = AI(\n",
    "        model_name=model,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    memory_path = input_path / \"memory\"\n",
    "    workspace_path = input_path / \"workspace\"\n",
    "    archive_path = input_path / \"archive\"\n",
    "    \n",
    "    shutil.copytree(existing_code_location, workspace_path)\n",
    "    \n",
    "    dbs = DBs(\n",
    "        memory=DB(memory_path),\n",
    "        logs=DB(memory_path / \"logs\"),\n",
    "        input=DB(input_path),\n",
    "        workspace=DB(workspace_path),\n",
    "        preprompts=DB(Path(steps.__file__).parent / \"preprompts\"),\n",
    "        archive=DB(archive_path),\n",
    "    )\n",
    "\n",
    "    dbs.workspace[\"all_output.txt\"] = all_code_from_files(existing_code_location)\n",
    "\n",
    "    return ai, dbs\n",
    "\n",
    "def all_code_from_files(path):\n",
    "    chat = \"These are the files implementing the code\\n\"\n",
    "    directory_path = path\n",
    "    file_pattern = \"**/*.*\"  # Match all files recursively\n",
    "\n",
    "    file_paths = glob.glob(os.path.join(directory_path, file_pattern), recursive=True)\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        file_name = os.path.relpath(file_path, start=directory_path)\n",
    "        file_content = read_file_to_string(file_path)\n",
    "        chat += \"**\" + file_name + \"**\\n\" + \"```\" + file_content + \"\\n```\\n\\n\"\n",
    "    return chat\n",
    "\n",
    "def read_file_to_string(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{file_path} not found.\")\n",
    "        return None\n",
    "        \n",
    "def do_step(step):\n",
    "    messages = step(ai, dbs)\n",
    "    dbs.logs[step.__name__] = AI.serialize_messages(messages)\n",
    "    \n",
    "def fix_code(how, add_default_end = True):\n",
    "    if add_default_end:\n",
    "        default_end = '''There might be placeholders in the code you have to fill in.\n",
    "You provide fully functioning, well formatted code with few comments, that works and has no bugs.\n",
    "Please return the full new code in the same format.\n",
    "'''\n",
    "        how = how + default_end\n",
    "    dbs.input['fix_prompt'] = how\n",
    "    do_step(steps.fix_code)\n",
    "\n",
    "\n",
    "ai, dbs = set_up(project_name, existing_code_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43d94c5-7bab-4cc6-9d02-f63c3345a7e5",
   "metadata": {},
   "source": [
    "#### Let's do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00bc5a70-d7d3-4ba5-ab14-9b8c5b634589",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fix_code('''You are an expert in optimizing scientific computations on HPC systems. \n",
    "You will help this scientist take their existing code and turn it into a Jupyter notebook \n",
    "utilizing dask with improved performance (faster, more interactive). \n",
    "Start by providing a short summary of the computation (DO NOT list out all the steps), followed by \n",
    "a short list of improvement suggestions for the following code.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bdee90-bd93-4485-a432-7d0df1ebdd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "fix_code('''Transform the existing code base such that the user interacts with a Jupyter notebook.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9de44c-2951-45cd-a624-8bc3599e73f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
