[{"type": "system", "data": {"content": "You are an expert in optimizing scientific computations on HPC systems. \nYou will help this scientist take their existing code and turn it into a Jupyter notebook \nutilizing dask with improved performance (faster, more interactive).\n\nUseful to know:\nYou almost always put different classes in different files.\nFor Python, you always create an appropriate requirements.txt file.\nFor NodeJS, you always create an appropriate package.json file.\nYou always add a comment briefly describing the purpose of the function definition.\nYou try to add comments explaining very complex bits of logic.\nYou always follow the best practices for the requested languages in terms of describing the code written as a defined\npackage/project.\n\n\nPython toolbelt preferences:\n- pytest\n- dataclasses\n", "additional_kwargs": {}}}, {"type": "human", "data": {"content": "Instructions: I have this scientific computation that I wrote. \nI would like to optimize it such that it runs faster (utilizing parallel computation) and is more interactive.\nI will be running this on an HPC system that has support for dask and slurm.\nI will want to interact with the computation via a Jupyter notebook.\n", "additional_kwargs": {}, "example": false}}, {"type": "human", "data": {"content": "These are the files implementing the code\n**WRF_EKE_NERSC_Ex.py**\n```from __future__ import division  # makes division not round with integers \nimport os\nfrom netCDF4 import Dataset\nimport numpy as np\nimport xarray as xr\nimport wrf as wrf\nfrom datetime import datetime\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nfrom matplotlib import rcParams\nimport matplotlib.patches as mpatches\nfrom matplotlib.backends.backend_pdf import PdfPages\nfrom matplotlib.colors import ListedColormap, LinearSegmentedColormap\nfrom scipy import signal\nimport scipy.ndimage as ndimage\n\n# This program calculates the eddy kinetic energy and plots the meridional\n# distribution. The equation used is EKE = [u'^2+v'^2]/2g\n# [ ] indicates a zonal average \n\n\n# This is a function to get the map projection and the lat and lon values from the WRF data\ndef lat_lon():\n\tfile_location = '/global/cscratch1/sd/ebercosh/WRF_TCM/Historical/wrfout_d01_2008-07-01_00_00_00'\n\tdata = Dataset(file_location)\n\t# get lat and lon values\n\t# get the latitude and longitude at a single time (since they don't change with time)\n\tlat = wrf.getvar(data, \"lat\") # ordered lat, lon\n\tlon = wrf.getvar(data, \"lon\") # ordered lat, lon\n\t# get the cropping indices since we don't want the lat/lon for the entire domain\n\tlon_index_west, lat_index_south = wrf.ll_to_xy(data,-10.,-40., meta=False) # 10S, 40W\n\tlon_index_east, lat_index_north = wrf.ll_to_xy(data,40.,30., meta=False) # 40N, 30E\n\tlat_crop = lat.values[lat_index_south:lat_index_north+1,lon_index_west:lon_index_east+1]\n\tlon_crop = lon.values[lat_index_south:lat_index_north+1,lon_index_west:lon_index_east+1]\n\t# get more zoomed in cropping indices\n\tlon_west = -20. # 20W\n\tlon_east = 20. # 20E\n\tlat_north = 20. # 20N\n\tlat_south = 0. # 0N\n\tlat_index_north = np.argmin((np.abs(lat_crop - lat_north)), axis=0)[0]\n\tlat_index_south = np.argmin((np.abs(lat_crop - lat_south)), axis=0)[0] \n\tlon_index_west = (np.abs(lon_crop - lon_west)).argmin() \n\tlon_index_east = (np.abs(lon_crop - lon_east)).argmin() \n\n\treturn lat_crop, lon_crop, lat_index_north, lat_index_south, lon_index_west, lon_index_east\n\n\n# filtering function to filter variables for waves with periods between 3-5 days \n# takes a variable where the first index (farthest to the left) must be time\n# returns a variable of the same dimensions as the original that has been temporally \n# filtered for 3-5 days using a Butterworth bandpass filter\ndef butter_bandpass_filter(variable):\n\tprint(\"Temporal filter...\")\n\torder = 6  # order of filtering, 6 is common\n\tfs = 1/6  # sampling rate is 1 sample every six hours\n\tnyq = .5 * fs  # Nyquist frequency is 1/2 times the sampling rate\n\tbig_period_day = 5.0    # band start (longer period)\n\tsmall_period_day = 3.0  # band end\n\tbig_period_hr = big_period_day*24.0  # convert the days to hours\n\tsmall_period_hr = small_period_day*24.0\n\tlow_frequency = (1/big_period_hr) / nyq     # 1 over the period to get the frequency and then\n\thigh_frequency = (1/small_period_hr) / nyq  # divide by the Nyquist frequency to normalize\n\tprint(low_frequency)\n\tprint(high_frequency)\n\tb, a = signal.butter(order, [low_frequency, high_frequency], btype='bandpass')\n\t# works on axis 0 (time)\n\tfiltered_variable = signal.lfilter(b, a, variable, axis=0)\n\treturn filtered_variable\n\n\ndef main():\n\t# set scenario type\n\tscenario_type = 'Historical'   #'Historical' # 'late_century'\n\n\tg = 9.8  # m/s^2 gravity acceleration\n\n\t# get cropped lat and lon\n\tlat, lon, lat_index_north, lat_index_south, lon_index_west, lon_index_east = lat_lon() \n\t\n\t# define two lists for holding EKE values over the ten years\n\teke_list = []\n\ttotal_eke_list = []\n\t# loop through years\n\tfor year in range(2001,2011):\n\t\tprint('Year =', year)\n\t\t# location of WRF file\n\t\tfile_location = '/global/cscratch1/sd/ebercosh/WRF_TCM/' + scenario_type + '/' + str(year) + '/'\n\n\t\t# get u and v\n\t\tu_data = xr.open_dataset(file_location + 'ua_' + scenario_type + '_' + str(year) + '.nc')\n\t\tv_data = xr.open_dataset(file_location + 'va_' + scenario_type + '_' + str(year) + '.nc')\n\t\tu_4d_full = u_data.ua # this is for May-November, ordered time, lev, lat, lon\n\t\tv_4d_full = v_data.va # this is for May-November, ordered time, lev, lat, lon\n\t\tprint(u_4d_full.shape)\n\t\tu_4d = u_4d_full[:-120,:,:,:] # don't include November, so go only to -120 (30 days * 4 times each day)\n\t\tv_4d = v_4d_full[:-120,:,:,:] # don't include November, so go only to -120 (30 days * 4 times each day)\n\t\tprint(u_4d.shape)\n\t\t\n\t\t# spatially filter u and v\n\t\tu_temp_filt = butter_bandpass_filter(u_4d)\n\t\tv_temp_filt = butter_bandpass_filter(v_4d)\n\n\t\t# square u' and v'\n\t\tuu = np.square(u_temp_filt)\n\t\tvv = np.square(v_temp_filt)\n\n\t\t# time average (on dim 0), order will then be lev, lat, lon\n\t\tuu_3d = np.mean(uu, axis = 0) \n\t\tvv_3d = np.mean(vv, axis = 0) \n\t\t\n\t\t# calculate u'^2 + v'^2 \n\t\tuu_vv_3d = uu_3d + vv_3d\n\n\t\t# zonal average\n\t\tuu_vv_2d = np.mean(uu_vv_3d[:,:,lon_index_west:lon_index_east+1], axis = 2) # order will be lev, lat\n\n\t\t# multiply by 0.5; then append eke_2d to the eke_list\n\t\teke_2d = 0.5*uu_vv_2d\n\t\teke_list.append(eke_2d)\n\t\tdel eke_2d\n\n\t\t# meridional average and multiply by 0.5 and divide by g\n\t\teke_1d = 0.5*np.mean(uu_vv_2d[:,lat_index_south:lat_index_north+1]/g, axis = 1) # order will be lev\n\n\t\t# integrate in pressure dim; append the total_eke to the total_eke_list\n\t\ttotal_eke = np.trapz(eke_1d, dx = 5000., axis=0)\n\t\ttotal_eke_list.append(total_eke)\n\t\tdel total_eke\n\n\t# average the lists\n\ttotal_eke_avg = np.mean(total_eke_list, axis=0)\n\tprint('10 year total EKE for', scenario_type, '=', total_eke_avg, 'J/m^2')\n\n\teke_avg = np.mean(eke_list, axis=0)\n\tprint(eke_avg.shape)\n\n\t# smooth array for plotting\n\teke_smooth = ndimage.gaussian_filter(eke_avg, sigma=0.9, order=0)\n\n\t# create plot\n\tfig, ax = plt.subplots()\n\tclevels = np.linspace(-8,8,33) #np.linspace(-14,14,29)  # contour levels\n\tcmap = plt.cm.PuOr \n\tunits = '$\\mathrm{m}^{2}$ $\\mathrm{s}^{-2}$'\n\t# define pressure levels for vertical cross setion\n\tp_levels = np.linspace(1000,100,19)\n\t# mesh the lat and vertical level values\n\tX,Y = np.meshgrid(lat[:,0],p_levels)  \n\tplt.xlabel(\"Latitude\")\n\tplt.ylabel(\"Pressure (hPa)\")\n\tcontours_fill = plt.contourf(X,Y,eke_avg, cmap=cmap, levels=clevels, extend=\"both\")\n\tax.set_xlim(-5,25)\n\tplt.minorticks_on()\n\tplt.gca().invert_yaxis()  # invert y axis, gca stands for \"get current axis\" and is a helper function\n\n\tcbar = plt.colorbar(contours_fill,  shrink = .58, orientation='horizontal') #, pad=.09) #shrink = .75,\n\n\t# square up plot axes\n\tax.set_aspect(1./ax.get_data_ratio())\n\n\t# save figure as a PDF\n\tfig.savefig('WRF_TCM_M-O_2001-2010avg_' + scenario_type + '_EKE.pdf', bbox_inches='tight')\n\n\n\nif __name__ == '__main__':\n\tmain()\n\n```\n\n", "additional_kwargs": {}, "example": false}}, {"type": "system", "data": {"content": "Provide a short summary of the computation (DO NOT list out all the steps) based on the provided code.\n", "additional_kwargs": {}}}, {"type": "human", "data": {"content": "Provide a short summary of the computation (DO NOT list out all the steps) based on the provided code.\n", "additional_kwargs": {}, "example": false}}, {"type": "ai", "data": {"content": "The code calculates the eddy kinetic energy (EKE) and plots the meridional distribution. It reads in WRF data for a given time period and filters the u and v variables for waves with periods between 3-5 days. It then calculates the square of the filtered u and v variables, averages them over time, and calculates the zonal average. The EKE is then multiplied by 0.5 and divided by the acceleration due to gravity. The meridional average is calculated and integrated over the pressure dimension. Finally, the total EKE and the averaged EKE are plotted and saved as a PDF file.", "additional_kwargs": {}, "example": false}}]