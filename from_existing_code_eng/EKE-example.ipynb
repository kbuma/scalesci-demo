{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f49c4f4e-f8a0-47cb-b288-d9426b4cec3f",
   "metadata": {},
   "source": [
    "### Rewriting EKE code to run more effectively on NERSC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1471068-ea0f-4451-b4f1-c9f62df52827",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Fill in the project name and existing code location."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c686aa3c-2f63-4662-9a00-560d03e2005e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "project_name = \"EKE\"\n",
    "existing_code_location = \"EKE-example-original\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f65e5a-27da-49a3-a644-303c01069988",
   "metadata": {},
   "source": [
    "#### Set up the AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a23a03a-6d96-484e-bdcc-27705aee8fc9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import shutil\n",
    "import glob\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import gpt_engineer.steps as steps\n",
    "from gpt_engineer.ai import AI, fallback_model\n",
    "from gpt_engineer.db import DB, DBs\n",
    "\n",
    "problem_statement = '''I have this scientific computation that I wrote. \n",
    "I would like to optimize it such that it runs faster (utilizing parallel computation) and is more interactive.\n",
    "I will be running this on an HPC system that has support for dask and slurm.\n",
    "I will want to interact with the computation via a Jupyter notebook.\n",
    "'''\n",
    "\n",
    "def set_up(project_name, existing_code_location):\n",
    "    input_path = Path(project_name)\n",
    "    input_path.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "    prompt_file = input_path / \"prompt\"\n",
    "\n",
    "    with open(prompt_file, \"w\") as file:\n",
    "        file.write(problem_statement)\n",
    "\n",
    "    input_path = input_path.absolute()\n",
    "    print(\"The following location will be used for processing\\nThe code will be output to the workspace directory of that location\")\n",
    "    print(input_path)\n",
    "    \n",
    "    model = \"gpt-4\"\n",
    "    temperature = 0.1\n",
    "    model = fallback_model(model)\n",
    "    ai = AI(\n",
    "        model_name=model,\n",
    "        temperature=temperature,\n",
    "    )\n",
    "\n",
    "    memory_path = input_path / \"memory\"\n",
    "    workspace_path = input_path / \"workspace\"\n",
    "    archive_path = input_path / \"archive\"\n",
    "    \n",
    "    shutil.copytree(existing_code_location, workspace_path)\n",
    "    \n",
    "    dbs = DBs(\n",
    "        memory=DB(memory_path),\n",
    "        logs=DB(memory_path / \"logs\"),\n",
    "        input=DB(input_path),\n",
    "        workspace=DB(workspace_path),\n",
    "        preprompts=DB(Path(steps.__file__).parent / \"preprompts\"),\n",
    "        archive=DB(archive_path),\n",
    "    )\n",
    "\n",
    "    dbs.workspace[\"all_output.txt\"] = all_code_from_files(existing_code_location)\n",
    "\n",
    "    return ai, dbs\n",
    "\n",
    "def all_code_from_files(path):\n",
    "    chat = \"These are the files implementing the code\\n\"\n",
    "    directory_path = path\n",
    "    file_pattern = \"**/*.*\"  # Match all files recursively\n",
    "\n",
    "    file_paths = glob.glob(os.path.join(directory_path, file_pattern), recursive=True)\n",
    "\n",
    "    for file_path in file_paths:\n",
    "        file_name = os.path.relpath(file_path, start=directory_path)\n",
    "        file_content = read_file_to_string(file_path)\n",
    "        chat += \"**\" + file_name + \"**\\n\" + \"```\" + file_content + \"\\n```\\n\\n\"\n",
    "    return chat\n",
    "\n",
    "def read_file_to_string(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            return file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"{file_path} not found.\")\n",
    "        return None\n",
    "        \n",
    "def do_step(step):\n",
    "    messages = step(ai, dbs)\n",
    "    dbs.logs[step.__name__] = AI.serialize_messages(messages)\n",
    "    \n",
    "def fix_code(how, add_default_end = True):\n",
    "    if add_default_end:\n",
    "        default_end = '''There might be placeholders in the code you have to fill in.\n",
    "You provide fully functioning, well formatted code with few comments, that works and has no bugs.\n",
    "Please return the full new code in the same format.\n",
    "'''\n",
    "        how = how + default_end\n",
    "    dbs.input['fix_prompt'] = how\n",
    "    do_step(steps.fix_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63bb92ea-b7fd-4cc2-afcf-a271a434bf1e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The following location will be used for processing\n",
      "The code will be output to the workspace directory of that location\n",
      "/Users/kberket/src/scalesci-demo/from_existing_code/EKE\n",
      "Model gpt-4 not available for provided API key. Reverting to gpt-3.5-turbo. Sign up for the GPT-4 wait list here: https://openai.com/waitlist/gpt-4-api\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ai, dbs = set_up(project_name, existing_code_location)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43d94c5-7bab-4cc6-9d02-f63c3345a7e5",
   "metadata": {},
   "source": [
    "#### Let's do it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00bc5a70-d7d3-4ba5-ab14-9b8c5b634589",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary of the computation:\n",
      "The code calculates the eddy kinetic energy (EKE) and plots the meridional distribution. It reads in WRF data files, filters the variables for waves with periods between 3-5 days, calculates the squared u' and v', averages them over time and longitude, and then calculates the zonal and meridional averages of EKE. Finally, it plots the meridional distribution of EKE.\n",
      "\n",
      "Improvement suggestions:\n",
      "1. Utilize parallel computation using dask to improve performance.\n",
      "2. Refactor the code into modular functions for better organization and reusability.\n",
      "3. Optimize the filtering function by using a more efficient algorithm.\n",
      "4. Use dataclasses to define structured data objects.\n",
      "5. Use pytest for testing.\n",
      "\n",
      "Here is the updated code:\n",
      "\n",
      "**WRF_EKE_NERSC_Ex.py**\n",
      "```python\n",
      "from __future__ import division\n",
      "import os\n",
      "from netCDF4 import Dataset\n",
      "import numpy as np\n",
      "import xarray as xr\n",
      "import wrf as wrf\n",
      "from datetime import datetime\n",
      "import matplotlib as mpl\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.ticker as mticker\n",
      "from matplotlib import rcParams\n",
      "import matplotlib.patches as mpatches\n",
      "from matplotlib.backends.backend_pdf import PdfPages\n",
      "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
      "from scipy import signal\n",
      "import scipy.ndimage as ndimage\n",
      "from dataclasses import dataclass\n",
      "import dask.array as da\n",
      "\n",
      "@dataclass\n",
      "class WRFData:\n",
      "    ua: xr.DataArray\n",
      "    va: xr.DataArray\n",
      "\n",
      "def lat_lon(file_location):\n",
      "    data = Dataset(file_location)\n",
      "    lat = wrf.getvar(data, \"lat\")\n",
      "    lon = wrf.getvar(data, \"lon\")\n",
      "    lat_index_west, lat_index_south = wrf.ll_to_xy(data, -10., -40., meta=False)\n",
      "    lon_index_east, lat_index_north = wrf.ll_to_xy(data, 40., 30., meta=False)\n",
      "    lat_crop = lat.values[lat_index_south:lat_index_north+1, lon_index_west:lon_index_east+1]\n",
      "    lon_crop = lon.values[lat_index_south:lat_index_north+1, lon_index_west:lon_index_east+1]\n",
      "    lon_west = -20.\n",
      "    lon_east = 20.\n",
      "    lat_north = 20.\n",
      "    lat_south = 0.\n",
      "    lat_index_north = np.argmin((np.abs(lat_crop - lat_north)), axis=0)[0]\n",
      "    lat_index_south = np.argmin((np.abs(lat_crop - lat_south)), axis=0)[0]\n",
      "    lon_index_west = (np.abs(lon_crop - lon_west)).argmin()\n",
      "    lon_index_east = (np.abs(lon_crop - lon_east)).argmin()\n",
      "    return lat_crop, lon_crop, lat_index_north, lat_index_south, lon_index_west, lon_index_east\n",
      "\n",
      "def butter_bandpass_filter(variable):\n",
      "    print(\"Temporal filter...\")\n",
      "    order = 6\n",
      "    fs = 1/6\n",
      "    nyq = .5 * fs\n",
      "    big_period_day = 5.0\n",
      "    small_period_day = 3.0\n",
      "    big_period_hr = big_period_day * 24.0\n",
      "    small_period_hr = small_period_day * 24.0\n",
      "    low_frequency = (1 / big_period_hr) / nyq\n",
      "    high_frequency = (1 / small_period_hr) / nyq\n",
      "    b, a = signal.butter(order, [low_frequency, high_frequency], btype='bandpass')\n",
      "    filtered_variable = signal.lfilter(b, a, variable, axis=0)\n",
      "    return filtered_variable\n",
      "\n",
      "def calculate_eke(uu_vv_2d, g):\n",
      "    eke_2d = 0.5 * uu_vv_2d\n",
      "    eke_1d = 0.5 * np.mean(uu_vv_2d[:, lat_index_south:lat_index_north+1] / g, axis=1)\n",
      "    total_eke = np.trapz(eke_1d, dx=5000., axis=0)\n",
      "    return eke_2d, total_eke\n",
      "\n",
      "def smooth_array(eke_avg):\n",
      "    eke_smooth = ndimage.gaussian_filter(eke_avg, sigma=0.9, order=0)\n",
      "    return eke_smooth\n",
      "\n",
      "def plot_eke(lat, p_levels, eke_avg):\n",
      "    fig, ax = plt.subplots()\n",
      "    clevels = np.linspace(-8, 8, 33)\n",
      "    cmap = plt.cm.PuOr\n",
      "    units = '$\\mathrm{m}^{2}$ $\\mathrm{s}^{-2}$'\n",
      "    X, Y = np.meshgrid(lat[:, 0], p_levels)\n",
      "    plt.xlabel(\"Latitude\")\n",
      "    plt.ylabel(\"Pressure (hPa)\")\n",
      "    contours_fill = plt.contourf(X, Y, eke_avg, cmap=cmap, levels=clevels, extend=\"both\")\n",
      "    ax.set_xlim(-5, 25)\n",
      "    plt.minorticks_on()\n",
      "    plt.gca().invert_yaxis()\n",
      "    cbar = plt.colorbar(contours_fill, shrink=.58, orientation='horizontal')\n",
      "    ax.set_aspect(1./ax.get_data_ratio())\n",
      "    fig.savefig('WRF_TCM_M-O_2001-2010avg_' + scenario_type + '_EKE.pdf', bbox_inches='tight')\n",
      "\n",
      "def process_year(year):\n",
      "    print('Year =', year)\n",
      "    file_location = '/global/cscratch1/sd/ebercosh/WRF_TCM/' + scenario_type + '/' + str(year) + '/'\n",
      "    u_data = xr.open_dataset(file_location + 'ua_' + scenario_type + '_' + str(year) + '.nc')\n",
      "    v_data = xr.open_dataset(file_location + 'va_' + scenario_type + '_' + str(year) + '.nc')\n",
      "    u_4d_full = u_data.ua\n",
      "    v_4d_full = v_data.va\n",
      "    u_4d = u_4d_full[:-120, :, :, :]\n",
      "    v_4d = v_4d_full[:-120, :, :, :]\n",
      "    u_temp_filt = butter_bandpass_filter(u_4d)\n",
      "    v_temp_filt = butter_bandpass_filter(v_4d)\n",
      "    uu = np.square(u_temp_filt)\n",
      "    vv = np.square(v_temp_filt)\n",
      "    uu_3d = np.mean(uu, axis=0)\n",
      "    vv_3d"
     ]
    }
   ],
   "source": [
    "fix_code('''You are an expert in optimizing scientific computations on HPC systems. \n",
    "You will help this scientist take their existing code and turn it into a Jupyter notebook \n",
    "utilizing dask with improved performance (faster, more interactive). \n",
    "Start by providing a short summary of the computation (DO NOT list out all the steps), followed by \n",
    "a short list of improvement suggestions for the following code.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bdee90-bd93-4485-a432-7d0df1ebdd67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**WRF_EKE_NERSC_Ex.py**\n",
      "```python\n",
      "from __future__ import division\n",
      "import os\n",
      "from netCDF4 import Dataset\n",
      "import numpy as np\n",
      "import xarray as xr\n",
      "import wrf as wrf\n",
      "from datetime import datetime\n",
      "import matplotlib as mpl\n",
      "import matplotlib.pyplot as plt\n",
      "import matplotlib.ticker as mticker\n",
      "from matplotlib import rcParams\n",
      "import matplotlib.patches as mpatches\n",
      "from matplotlib.backends.backend_pdf import PdfPages\n",
      "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
      "from scipy import signal\n",
      "import scipy.ndimage as ndimage\n",
      "from dataclasses import dataclass\n",
      "import dask.array as da\n",
      "\n",
      "@dataclass\n",
      "class WRFData:\n",
      "    ua: xr.DataArray\n",
      "    va: xr.DataArray\n",
      "\n",
      "def lat_lon(file_location):\n",
      "    data = Dataset(file_location)\n",
      "    lat = wrf.getvar(data, \"lat\")\n",
      "    lon = wrf.getvar(data, \"lon\")\n",
      "    lat_index_west, lat_index_south = wrf.ll_to_xy(data, -10., -40., meta=False)\n",
      "    lon_index_east, lat_index_north = wrf.ll_to_xy(data, 40., 30., meta=False)\n",
      "    lat_crop = lat.values[lat_index_south:lat_index_north+1, lon_index_west:lon_index_east+1]\n",
      "    lon_crop = lon.values[lat_index_south:lat_index_north+1, lon_index_west:lon_index_east+1]\n",
      "    lon_west = -20.\n",
      "    lon_east = 20.\n",
      "    lat_north = 20.\n",
      "    lat_south = 0.\n",
      "    lat_index_north = np.argmin((np.abs(lat_crop - lat_north)), axis=0)[0]\n",
      "    lat_index_south = np.argmin((np.abs(lat_crop - lat_south)), axis=0)[0]\n",
      "    lon_index_west = (np.abs(lon_crop - lon_west)).argmin()\n",
      "    lon_index_east = (np.abs(lon_crop - lon_east)).argmin()\n",
      "    return lat_crop, lon_crop, lat_index_north, lat_index_south, lon_index_west, lon_index_east\n",
      "\n",
      "def butter_bandpass_filter(variable):\n",
      "    print(\"Temporal filter...\")\n",
      "    order = 6\n",
      "    fs = 1/6\n",
      "    nyq = .5 * fs\n",
      "    big_period_day = 5.0\n",
      "    small_period_day = 3.0\n",
      "    big_period_hr = big_period_day * 24.0\n",
      "    small_period_hr = small_period_day * 24.0\n",
      "    low_frequency = (1 / big_period_hr) / nyq\n",
      "    high_frequency = (1 / small_period_hr) / nyq\n",
      "    b, a = signal.butter(order, [low_frequency, high_frequency], btype='bandpass')\n",
      "    filtered_variable = signal.lfilter(b, a, variable, axis=0)\n",
      "    return filtered_variable\n",
      "\n",
      "def calculate_eke(uu_vv_2d, g):\n",
      "    eke_2d = 0.5 * uu_vv_2d\n",
      "    eke_1d = 0.5 * np.mean(uu_vv_2d[:, lat_index_south:lat_index_north+1] / g, axis=1)\n",
      "    total_eke = np.trapz(eke_1d, dx=5000., axis=0)\n",
      "    return eke_2d, total_eke\n",
      "\n",
      "def smooth_array(eke_avg):\n",
      "    eke_smooth = ndimage.gaussian_filter(eke_avg, sigma=0.9, order=0)\n",
      "    return eke_smooth\n",
      "\n",
      "def plot_eke(lat, p_levels, eke_avg):\n",
      "    fig, ax = plt.subplots()\n",
      "    clevels = np.linspace(-8, 8, 33)\n",
      "    cmap = plt.cm.PuOr\n",
      "    units = '$\\mathrm{m}^{2}$ $\\mathrm{s}^{-2}$'\n",
      "    X, Y = np.meshgrid(lat[:, 0], p_levels)\n",
      "    plt.xlabel(\"Latitude\")\n",
      "    plt.ylabel(\"Pressure"
     ]
    }
   ],
   "source": [
    "fix_code('''Transform the existing code base such that the user interacts with a Jupyter notebook.''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9de44c-2951-45cd-a624-8bc3599e73f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
